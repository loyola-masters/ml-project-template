[Back to `README.md`](../README.md)

## üê≥ 4) Docker setup & quick start

Docker permite empaquetar el entorno de desarrollo y ejecuci√≥n en **contenedores reproducibles**.
As√≠, todos los alumnos ejecutan el proyecto con las **mismas versiones** de Python, librer√≠as y dependencias, sin problemas de instalaci√≥n local.

### üì¶ Instalaci√≥n de Docker

#### Windows (con WSL2)

1. Instalar **Docker Desktop** desde: [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)
2. Durante la instalaci√≥n, activar la opci√≥n **‚ÄúUse WSL 2 based engine‚Äù**.
3. Al terminar, reinicia el sistema y comprueba:
   ```powershell
   docker --version
   docker run hello-world
   ```

Si ves el mensaje *Hello from Docker!*, todo est√° correcto.

#### macOS

1. Descarga **Docker Desktop for Mac** (Intel o Apple Silicon) en el mismo enlace.
2. Inst√°lalo y arranca la app Docker Desktop.
3. Comprueba en terminal:

   ```bash
   docker --version
   docker run hello-world
   ```

#### IMPORTANTE: Instalaci√≥n en Windows vs. Ubuntu WSL

1. **Docker Desktop en Windows**

   * Instala su propio motor de Docker, pero **lo hace sobre WSL2** (ya no sobre Hyper-V como antes).
   * Por eso durante la instalaci√≥n aparece ‚ÄúUse the WSL2 based engine‚Äù.
   * Crea una distro interna llamada `docker-desktop` en WSL para gestionar contenedores.
   
   Este modo de instalaci√≥n permite tener disponible Docker tanto en Windows como en WSL. 

2. **S√≥lo para Ubuntu en WSL**

   * WSL es una distro aparte (ej. `Ubuntu-22.04`).
   * Aqu√≠ puedes instalar **otro engine de Docker** usando `apt install docker-ce`.
3. **Posible conflicto**

   * Si instalas Docker *dentro de Ubuntu-WSL* y adem√°s usas Docker Desktop, tendr√°s **dos motores Docker distintos**:

     * `docker` en Ubuntu apunta al daemon de esa distro.
     * `docker` en Windows (via Docker Desktop) apunta al daemon del `docker-desktop`.
   * Esto causa confusi√≥n: im√°genes, contenedores y redes no son compartidas entre ambos motores.
4. **Recomendaci√≥n**

   Usa Docker Desktop como motor √∫nico. Desde tu Ubuntu-WSL, el cliente `docker` se conecta autom√°ticamente al daemon de Docker Desktop (si tienes habilitada la integraci√≥n con tu distro en ‚ÄúSettings ‚Üí Resources ‚Üí WSL Integration‚Äù).

---

### Hands On: Quickstart del proyecto con Docker

1. En la ra√≠z del repo tienes un `Dockerfile` m√≠nimo. Construye la imagen:

   ```bash
   docker build -t ml-template .
   ```
2. Lanza un contenedor interactivo:

   ```bash
   docker run -it --rm -v $(pwd):/workspace ml-template bash
   ```

   * `-v $(pwd):/workspace` monta tu carpeta local dentro del contenedor.
   * As√≠ puedes editar c√≥digo en tu editor y ejecutarlo dentro de Docker.
   * `--rm` elimina el contenedor al salir de √©l
3. Ejecutar el flujo de ejemplo (Iris):

   ```bash
   make setup
   make test
   make train
   ```

Cuando ejecutes `make setup` el terminal te avisar√° de que el environment de `uv` ya existe. Responde `yes` para sobreescribirlo con el setup de tu proyecto. Tras la ejecuci√≥n, los artefactos (`runs/...`) quedar√°n en tu carpeta local, accesibles fuera del contenedor.

**TIP**: Sin `bash` ejecuta el comando por defecto en `Dockerfile`, i.e. `CMD ["make", "setup", "test", "train"]`:

```bash
   docker run -it --rm -v $(pwd):/workspace ml-template
```

#### Verificaci√≥n

* `docker ps` ‚Üí lista contenedores activos.
* `docker images` ‚Üí lista im√°genes locales.
* Comprueba que tras `make train` se genera un directorio `runs/AAAAmmdd_HHMMSS/` con modelo y m√©tricas.

> Tips
>
> * Para liberar espacio: `docker system prune -a`

---

### ANEXO: **Instalaci√≥n GPU (Ubuntu / WSL2)**

* Si trabajas con **GPU (NVIDIA)**: instala tambi√©n `nvidia-docker2` y a√±ade flag `--gpus all` al `docker run`:
  * `nvidia-docker2` es un **complemento para Docker** que permite que los contenedores accedan a la **GPU NVIDIA** instalada en tu equipo.
  * Internamente usa el *NVIDIA Container Toolkit*, que conecta los drivers de tu m√°quina con el contenedor.
  * As√≠, puedes entrenar modelos en GPU dentro de Docker sin tener que instalar CUDA/cuDNN manualmente en la imagen.

- Para Ubuntu:

1. A√±adir el repositorio oficial:

   ```bash
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
   ```
2. Instalar paquete:

   ```bash
   sudo apt update
   sudo apt install -y nvidia-docker2
   ```
3. Reiniciar Docker:

   ```bash
   sudo systemctl restart docker
   ```

- Para WSL:
  *(En Windows con WSL2, basta con instalar los drivers NVIDIA + Docker Desktop con soporte WSL2 y marcar la opci√≥n GPU en settings.)*

---

Una vez instalado el toolkit, construye la nueva imagen:

```bash
docker build -t ml-template-gpu -f Dockerfile_gpu
```
El fichero para construir la imagen es `Dockerfile_gpu`, junto con CUDA se instala Pytorch, para la versi√≥n 12.4 de CUDA
Al ejecutar un contenedor solo necesitas a√±adir la opci√≥n `--gpus all`, que expone todas las GPUs disponibles.

**‚úÖ Verificaci√≥n dentro del contenedor**: Entra y ejecuta:

```bash
# En el host
docker run -it --rm --gpus all ml-template-gpu bash

# Y ya dentro del contenedor
nvidia-smi
```

Comprueba la informaci√≥n de la tarjeta gr√°fica.

Puedes limitar, por ejemplo, a la GPU 0:

```bash
docker run -it --rm --gpus '"device=0"' ml-template-uv bash
```

**Ejecuci√≥n del proyecto:**

```bash
docker run -it --rm --gpus all ml-template-gpu
```
