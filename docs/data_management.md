# [1] Comparativa de opciones para datasets

| Criterio                         | **Git LFS**                                          | **DagsHub**                                                | **Hugging Face (HF Datasets)**                             |
| -------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- |
| **Qu√© es**                | Extensi√≥n de Git para ficheros grandes                    | Plataforma Git + ML stack (repos, data, modelos, experimentos)   | Repositorio abierto para datasets y modelos ML                   |
| **D√≥nde viven los datos** | En tu mismo repo Git, pero almacenados como punteros LFS   | En repos DagsHub (sobre GitHub/GitLab/Bitbucket + LFS integrado) | En el Hub de Hugging Face (`datasets/tuusuario/...`)           |
| **Tama√±o soportado**      | Hasta GBs por fichero, pero depende del plan GitHub/GitLab | Similar a Git LFS (con l√≠mites altos en plan free)              | Repos p√∫blicos: hasta 50 GB gratis; Enterprise para m√°s        |
| **Integraci√≥n con ML**    | Ninguna, solo Git                                          | ‚úÖ DVC integrado, MLflow, data lineage, versionado               | ‚úÖ Integraci√≥n directa con `datasets`de HF y `transformers` |
| **Acceso**                 | Clonado con `git lfs pull`(requiere LFS habilitado)      | HTTP(S), Git LFS, DVC, API de DagsHub                            | HTTP(S),`datasets.load_dataset()`, git clone                   |
| **Versionado de datos**    | B√°sico (versiones Git)                                    | ‚úÖ Tracking de datos, versiones, lineage                         | ‚úÖ Cada dataset tiene versiones, splits y ‚Äúrevisions‚Äù          |
| **Privacidad**             | Respeta privacidad del repo (privado/p√∫blico)             | Repos privados/p√∫blicos, control granular                       | P√∫blico por defecto; privado solo con cuenta pro                |
| **Coste**                  | Depende de hosting (GitHub LFS = 1 GB free, luego pago)    | Free tier generosa, planes premium para m√°s                     | Gratis para datasets p√∫blicos (hasta 50 GB)                     |
| **Facilidad de uso**       | Muy f√°cil si ya usas Git                                  | Interfaz clara para ML teams, unifica c√≥digo+data+experimentos  | Muy simple para comunidad ML, API Python lista                   |
| **Casos ideales**          | Proyectos peque√±os o medianos con datos internos          | Equipo ML colaborativo que quiere todo en un mismo sitio         | Difusi√≥n p√∫blica de datasets para la comunidad ML              |

---

**Git LFS** :

* Pros: Simplicidad (sigues en Git).
* Contras: Muy limitado en **GitHub Free** (1 GB de almacenamiento LFS + 1 GB/mes de transferencia). Tus 8.000 alumnos en grafos ‚Üí dataset grande ‚Üí se queda corto enseguida.
* **DagsHub** :
* Pros: Integraci√≥n brutal para proyectos de ML colaborativos ‚Üí repos de datos, experiment tracking (MLflow), DVC, visualizaci√≥n. Ideal para  **equipo de investigaci√≥n** .
* Contras: Menos conocido que HF, requiere que todos los alumnos tengan cuenta.
* **Hugging Face** :
* Pros: Perfecto si quieres **compartir datasets p√∫blicos** de sociogramas (estandariza acceso v√≠a `datasets.load_dataset()`). Muy √∫til si vas a publicar o dar clase y quieres que alumnos lo carguen f√°cil.
* Contras: Menos pr√°ctico si los datos son **sensibles o privados** (sociogramas escolares tienen privacidad alta). Para privado, necesitas plan pago.

---

## üö¶ Recomendaci√≥n pr√°ctica para tu proyecto

1. **Datos sensibles (no p√∫blicos)**
   * Usa **DagsHub repo privado** ‚Üí tienes control, versi√≥n, lineage, integraci√≥n con tus pipelines.
   * Alternativa m√≠nima: **Git LFS privado** en GitHub, pero ojo con cuotas.
2. **Datos p√∫blicos (an√≥nimos, listos para compartir con la comunidad)**
   * Usa **Hugging Face Datasets Hub** ‚Üí alumnos y otros investigadores los cargan con una l√≠nea:
     ```python
     from datasets import load_dataset
     ds = load_dataset("tuusuario/sociogramas_escolares")
     ```

---

# [2] Flujo de integraci√≥n GitHub ‚Üî DagsHub

La idea es mantener:

* **C√≥digo y notebooks** en **GitHub** (repo principal).
* **Datasets** en **DagsHub** (repositorio de datos, versionado y acceso f√°cil).
* Conexi√≥n: los alumnos clonan solo el c√≥digo y luego tiran del dataset desde DagsHub.

**üîß Pasos de configuraci√≥n inicial (profesor/admin)**

1. **Crear cuenta en [DagsHub](https://dagshub.com/)**
   * Puedes loguearte con tu GitHub para sincronizar repos.
2. **Conectar tu repositorio de GitHub**
   * En DagsHub ‚Üí *Import Repository* ‚Üí selecciona el repo `ml-project-template`.
   * Esto crea un espejo (c√≥digo y ramas siguen sincronizados.
3. **Crear un repositorio de datos**
   * En DagsHub puedes tener un repo separado solo para datasets (`ml-project-data`).
   * Sube all√≠ los CSV/JSON/NPZ/etc. de ejemplo.
   * Se versionan con **DVC** o **Git LFS** (DagsHub ya trae ambos integrados).
4. **Configurar acceso**
   * Si los datasets son de clase ‚Üí repo privado y dar acceso solo a los alumnos.
   * Si son p√∫blicos (ejemplo Iris, MNIST) ‚Üí repo p√∫blico.

**üìÇ Estructura del repositorio**

* `github.com/tuproyecto/ml-project-template`
  * `src/`
  * `configs/`
  * `notebooks/`
  * `Makefile`
  * `README.md` (con instrucciones para bajar dataset de DagsHub)
* `dagshub.com/tuproyecto/ml-project-data`
  * `data/raw/...`
  * `data/processed/...`
  * `dvc.yaml` (si usas DVC para versionado)
  * `README.md` (documentando dataset)

---

## üîó C√≥mo consumen los datos los alumnos

**Opci√≥n A ‚Äì v√≠a Git clone (con Git LFS o DVC activado)**

En `README.md` del proyecto pones:

```bash
# Clonar repo de datos con DagsHub (ejemplo con LFS)
git clone https://dagshub.com/<user>/ml-project-data.git
cd ml-project-data
git lfs pull
```

Y luego en el proyecto principal (`ml-project-template`) apuntas a `../ml-project-data/data/...`.

---

**Opci√≥n B ‚Äì v√≠a URL HTTP (sin clonar todo)**

DagsHub expone datos como archivos est√°ticos v√≠a HTTPS.

Ejemplo en Python:

```python
import pandas as pd

url = "https://dagshub.com/<user>/ml-project-data/raw/main/data/iris.csv"
df = pd.read_csv(url)
```

Esto es muy c√≥modo para alumnos ‚Üí no necesitan configurar LFS ni DVC, solo Pandas.

---

**Opci√≥n C ‚Äì v√≠a DVC remote**

Si usas  **DVC** :

1. A√±ades en el repo de c√≥digo un `.dvc` que apunte al dataset.
2. Los alumnos hacen:

```bash
dvc pull
```

y obtienen exactamente la versi√≥n de datos ligada al commit de c√≥digo.


---

**üìå Ventajas frente a tener `./data` en GitHub**

* Mantienes el repo de c√≥digo **ligero** (solo notebooks y scripts).
* Versionas datasets con DVC o LFS sin comerte las cuotas de GitHub.
* Puedes tener **privacidad granular** (repo de c√≥digo p√∫blico, datasets privados).
* DagsHub a√±ade capa de **tracking de experimentos** (MLflow integrado), por si m√°s adelante quieres ense√±ar a los alumnos c√≥mo registrar m√©tricas.

---

# [3] Integraci√≥n MLflow + DagsHub

MLflow permite:

* **Trackear experimentos** ‚Üí hiperpar√°metros, m√©tricas, artefactos (ej. modelos, gr√°ficos).
* **Comparar runs** ‚Üí ver qu√© configuraci√≥n de entrenamiento dio mejores resultados.
* **Guardar modelos reproducibles** .

DagsHub integra **MLflow Tracking Server** directamente:

* Cada repo de DagsHub viene con un endpoint MLflow listo para usar (`https://dagshub.com/<user>/<repo>.mlflow`).
* No necesitas montar tu propio servidor MLflow en local.
* Permite que **todos los alumnos/trabajadores vean los mismos experimentos** desde la interfaz web.

## Pasos de configuraci√≥n

**a) Crear el repo en DagsHub**

* Tu repo de c√≥digo (`ml-project-template`) ya puede estar importado desde GitHub a DagsHub.
* Activa la pesta√±a **Experiments** ‚Üí DagsHub habilita autom√°ticamente un servidor MLflow.

**b) Autenticaci√≥n**

Cada usuario necesita un  **token personal de DagsHub** :

1. Ir a  *Profile ‚Üí Settings ‚Üí Access Tokens* .
2. Crear token con permisos de `write:repo`.
3. Guardar en variable de entorno (Linux/WSL):

```bash
export MLFLOW_TRACKING_USERNAME=<tu_usuario>
export MLFLOW_TRACKING_PASSWORD=<tu_token>
```

**c) Configurar** `MLFLOW_TRACKING_URI`

En el entorno del proyecto (puede ir en `Makefile` o en `.env`):

```bash
export MLFLOW_TRACKING_URI=https://dagshub.com/<user>/<repo>.mlflow
```

 Las variables `MLFLOW_TRACKING_USERNAME `y `MLFLOW_TRACKING_PASSWORD `son las credenciales que permiten a tus alumnos (o a ti)  **autenticarse en el servidor MLflow que expone DagsHub** .

Para crearlas:

1. **En tu cuenta de DagsHub**
   * Ve a tu perfil ‚Üí  **Settings ‚Üí Access Tokens** .
   * Crea un **Personal Access Token** con permisos de lectura/escritura sobre repos.
   * Ese token servir√° como `MLFLOW_TRACKING_PASSWORD`.
2. **Asignaci√≥n de las variables**
   * `MLFLOW_TRACKING_USERNAME` ‚Üí tu **usuario de DagsHub** (ejemplo: `dcanales-lu`).
   * `MLFLOW_TRACKING_PASSWORD` ‚Üí el **token generado** en el paso anterior.

Incluirlas en el fichero `.env` en la ra√≠z del repo:

```bash
MLFLOW_TRACKING_URI=https://dagshub.com/<usuario>/<repo>.mlflow
MLFLOW_TRACKING_USERNAME=<usuario_dagshub>
MLFLOW_TRACKING_PASSWORD=<token_personal>
```

Ejemplo:

```bash
MLFLOW_TRACKING_URI=https://dagshub.com/dcanales-lu/ml-project-template.mlflow
MLFLOW_TRACKING_USERNAME=dcanales-lu
MLFLOW_TRACKING_PASSWORD=ghp_XXXXXXXXXXXXXXXXXXXXX
```

**C√≥mo se usan en el c√≥digo**. Con `python-dotenv`:

```python

```

Cuando ejecutes un `mlflow.start_run()`, quedar√° registrado directamente en el servidor de DagsHub.

**C√≥digo de ejemplo en** `src/app/train_mlflow.py`

---

**Flujo para los alumnos**

1. Clonan tu repo de GitHub.
2. Configuran `.env` con `MLFLOW_TRACKING_URI`, `MLFLOW_TRACKING_USERNAME`, `MLFLOW_TRACKING_PASSWORD`.
3. Ejecutar experimentos con diferentes configs.  `make train`.

* El run aparece en **DagsHub ‚Üí Experiments** con:
  * Par√°metros (`max_depth`)
  * M√©tricas (`accuracy`)
  * Artefactos (modelo serializado, plots, logs).

DagsHub genera tablas y gr√°ficas comparativas entre runs autom√°ticamente. Los resultados consolidados en la web de DagsHub, sin instalar nada m√°s.

---

## ¬øD√≥nde va alojado `.env`?

* Debe estar en la  **ra√≠z del proyecto** , junto a `pyproject.toml`, `Makefile`, etc.:
  ```
  ml-project-template/
  ‚îú‚îÄ‚îÄ .env
  ‚îú‚îÄ‚îÄ Makefile
  ‚îú‚îÄ‚îÄ pyproject.toml
  ‚îú‚îÄ‚îÄ src/
  ‚îú‚îÄ‚îÄ configs/
  ‚îî‚îÄ‚îÄ ...
  ```
* Se a√±ade a  **`.gitignore`** , para que **no se suba nunca a GitHub/DagsHub** (evitamos exponer tokens).
* Puedes dejar un fichero de ejemplo (`.env.example`) en el repo con variables vac√≠as para que los alumnos lo copien:
  ```bash
  MLFLOW_TRACKING_URI=https://dagshub.com/<user>/<repo>.mlflow
  MLFLOW_TRACKING_USERNAME=
  MLFLOW_TRACKING_PASSWORD=
  ```

---

## ¬øC√≥mo se cargan las variables de `.env`?

1. **Desde Python (recomendado para tu plantilla)**

Usa la librer√≠a [`python-dotenv`](https://pypi.org/project/python-dotenv/):

```python
from dotenv import load_dotenv
import os

# Cargar autom√°ticamente el .env desde la ra√≠z
load_dotenv()

mlflow_uri = os.getenv("MLFLOW_TRACKING_URI")
mlflow_user = os.getenv("MLFLOW_TRACKING_USERNAME")
mlflow_pass = os.getenv("MLFLOW_TRACKING_PASSWORD")
```

---

2. **Desde la shell (alternativa manual)**

En Linux/WSL/Mac:

```bash
export $(grep -v '^#' .env | xargs)
```

En PowerShell (Windows):

```powershell
Get-Content .env | ForEach-Object {
  if ($_ -match "^(.*)=(.*)$") {
    Set-Item -Path Env:$($matches[1]) -Value $matches[2]
  }
}
```

Esto carga todas las variables del `.env` en el entorno actual.


---

**üìå Resumen de buenas pr√°cticas en tu plantilla**

1. En la ra√≠z: `.env` (privado) y `.env.example` (p√∫blico).
2. A√±adir a `.gitignore`:
   ```
   .env
   ```
3. En `train.py`, llamar siempre a `load_dotenv()` antes de usar `os.getenv()`.
4. Documentar en el `README.md` ‚Üí "Copia `.env.example` a `.env` y rellena tus credenciales".
